# Stand-up Comedy Transcripts Analysis using NLP

This project involves analyzing transcripts from various stand-up comedians and identifying similarities and differences in their style of comedy. We will also be exploring ways to generate new text based on the analyzed data.

### Notebooks
1. [Data Cleaning](https://github.com/sailohitaksh-cryptic/Stand-up-Comedy-Transcripts-Analysis-using-NLP/blob/main/NLP%20in%20Python%202.ipynb): In this notebook, we will clean and preprocess the data to prepare it for further analysis.

2. [Exploratory Data Analysis](https://github.com/sailohitaksh-cryptic/Stand-up-Comedy-Transcripts-Analysis-using-NLP/blob/main/NLP%20in%20Python%203.ipynb): In this notebook, we will perform exploratory data analysis to find patterns and insights in the data.

3. [Sentiment Analysis](https://github.com/sailohitaksh-cryptic/Stand-up-Comedy-Transcripts-Analysis-using-NLP/blob/main/NLP%20in%20Python%204%20(Sentiment%20Analysis).ipynb): In this notebook, we will use the TextBlob module to perform sentiment analysis on the transcripts.

4. [Topic Modeling](https://github.com/sailohitaksh-cryptic/Stand-up-Comedy-Transcripts-Analysis-using-NLP/blob/main/NLP%20in%20Python%205%20(Topic-Modeling).ipynb): In this notebook, we will use the Latent Dirichlet Allocation (LDA) algorithm to identify topics present in the transcripts.

5. [Text Generation](https://github.com/sailohitaksh-cryptic/Stand-up-Comedy-Transcripts-Analysis-using-NLP/blob/main/NLP%20in%20Python%206%20(Text-Generation).ipynb): In this notebook, we will use Markov chains to generate new text based on the analyzed data.

### Getting Started
To run these notebooks on your local machine, you will need to install the following dependencies:

* Python 3.x
* Jupyter Notebook
* Pandas
* NLTK
* TextBlob
* Gensim
* PyLDAvis
* Wordcloud
* sklearn

Once you have installed the dependencies, clone this repository to your local machine and navigate to the notebooks directory. From there, you can open each notebook in Jupyter Notebook and run the code.

### Data
The data used in this project consists of transcripts from various stand-up comedians, which can be found in the data directory. The transcripts were scraped from Scraps From The Loft and IMDb.

### Conclusion
This project demonstrates how natural language processing techniques can be used to analyze text data and generate new text. I hope this serves as a useful resource for those interested in text analysis and generation.
